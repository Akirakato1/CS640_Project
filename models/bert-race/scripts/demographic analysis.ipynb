{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "user_demo=pd.read_json(\"./User demo profiles.json\")\n",
    "user_demo[\"user_id\"]=user_demo[\"id\"]\n",
    "labeled_users=pd.read_csv(\"./labeled_users.csv\")\n",
    "labeled_users[\"user_id\"]=pd.to_numeric(labeled_users[\"user_id\"], downcast=\"integer\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   race     0\n",
      "0   1.0   328\n",
      "1   2.0   203\n",
      "2   3.0   116\n",
      "3   4.0  2792\n",
      "4   5.0   133\n",
      "   year_born     0\n",
      "0      False  3594\n",
      "1       True    13\n",
      "              id                                 name      screen_name  \\\n",
      "0          12488                           Chad Boyce         djsnipa1   \n",
      "1         719703                             Tomato ðŸ˜·           Tomato   \n",
      "2         722153                                blank            blank   \n",
      "3         749003  A ring made from a spoon --- E83.31            IYQbd   \n",
      "4         811618                                 Mr.O      Putanginamo   \n",
      "...          ...                                  ...              ...   \n",
      "3602  4895390642                    Dalton's Eyeliner  FlyAwayEyeliner   \n",
      "3603  4895831833                         Jamie Loftus    cowboyjamie77   \n",
      "3604  4921995243                                saved         memelady   \n",
      "3605  4924158634                  Winter da CoffeeCat     WinterStar21   \n",
      "3606  4928657861                 magical fluff nugget      ohitspotato   \n",
      "\n",
      "                                            description lang  \\\n",
      "0     Multimedia Developer, Graphic Designer, DJ, an...   NA   \n",
      "1                                            ðŸ‡­ðŸ‡°Rise Up!   NA   \n",
      "2         Someone who thinks too much, acts too little.   NA   \n",
      "3     Has the kind of luck that turns a professional...   NA   \n",
      "4     http://t.co/UfipjuQ2Mw is a blog and talk show...   NA   \n",
      "...                                                 ...  ...   \n",
      "3602  I'm Dalton's eyeliner, who are you? Are you Da...   NA   \n",
      "3603  41 year old male. interests include learning, ...   NA   \n",
      "3604                                                      NA   \n",
      "3605  Big fan of cats, coffee, horror stuff and anim...   NA   \n",
      "3606  ADHD and all that fun stuff. Future counselor....   NA   \n",
      "\n",
      "                     img_path     user_id  is_female  year_born  race  \n",
      "0     profile pics/60147.jpeg       12488        0.0     1980.0   4.0  \n",
      "1     profile pics/60148.jpeg      719703        0.0     1985.0   4.0  \n",
      "2     profile pics/60149.jpeg      722153        1.0     1973.0   3.0  \n",
      "3     profile pics/60150.jpeg      749003        0.0     1982.0   5.0  \n",
      "4     profile pics/60152.jpeg      811618        0.0     1987.0   3.0  \n",
      "...                       ...         ...        ...        ...   ...  \n",
      "3602  profile pics/64267.jpeg  4895390642        0.0     1976.0   2.0  \n",
      "3603  profile pics/64268.jpeg  4895831833        0.0     1977.0   4.0  \n",
      "3604  profile pics/64269.jpeg  4921995243        1.0     1996.0   4.0  \n",
      "3605  profile pics/64270.jpeg  4924158634        1.0     1983.0   4.0  \n",
      "3606  profile pics/64271.jpeg  4928657861        1.0     1996.0   4.0  \n",
      "\n",
      "[3607 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "df=pd.merge(user_demo, labeled_users, left_on=\"user_id\", right_on=\"user_id\")\n",
    "race_count=df.groupby(\"race\").size().reset_index()\n",
    "lt_21=((2021-df[\"year_born\"])<21).reset_index().groupby(\"year_born\").size().reset_index()\n",
    "print(race_count)\n",
    "print(lt_21)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "text_file = open(\"./Twitter_User_Handles_labeled_tweets.json\", \"r\", encoding='utf-8')\n",
    "data = text_file.read()\n",
    "text_file.close()\n",
    "tweets = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re \n",
    "\n",
    "users=list(tweets.keys())\n",
    "def remove_punctuation(tweet):\n",
    "    punctuation=[\".\",\",\",\":\",\";\",\"!\",\"?\"]\n",
    "    for p in punctuation:\n",
    "        tweet=tweet.replace(p, \"\")\n",
    "    return tweet\n",
    "\n",
    "def extract(tweet):\n",
    "    tweet=remove_punctuation(tweet).lstrip().split(\" \")\n",
    "    tweet=list(filter(lambda x: len(x)>0, tweet))\n",
    "    ats=list(filter(lambda x: x[0]==\"@\", tweet))\n",
    "    hashtags=list(filter(lambda x: x[0]==\"#\",tweet))\n",
    "    clean=list(filter(lambda x: x[0]!=\"@\" and x[0]!=\"#\" and x[0:4]!=\"http\", tweet))\n",
    "    return \" \".join(clean), \" \".join(ats), \" \".join(hashtags)\n",
    "\n",
    "def create_excel(users,indexes):\n",
    "    users=users[indexes[0]:indexes[1]]\n",
    "    df = pd.DataFrame(columns = ['user_id', 'clean_text', '@','#'])\n",
    "    for user in users:\n",
    "        for tweet in tweets[user]:\n",
    "            clean, ats, hashtags = extract(tweet)\n",
    "            df = df.append({'user_id':user, 'clean_text':clean, '@':ats,'#':hashtags},ignore_index=True)\n",
    "\n",
    "    df.to_excel(\"cleaned_tweets\"+str(indexes)+\".xlsx\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes=[[0,1000],[1000,2000],[2000,3000],[3000,len(users)]]\n",
    "create_excel(users, indexes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_excel(users, indexes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_excel(users, indexes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_excel(users, indexes[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=pd.read_excel(\"./cleaned_tweets[0, 1000].xlsx\",engine='openpyxl')\n",
    "df2=pd.read_excel(\"./cleaned_tweets[1000, 2000].xlsx\",engine='openpyxl')\n",
    "df3=pd.read_excel(\"./cleaned_tweets[2000, 3000].xlsx\",engine='openpyxl')\n",
    "df4=pd.read_excel(\"./cleaned_tweets[3000, 3276].xlsx\",engine='openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge=df1.append(df2, ignore_index = True)\n",
    "merge=merge.append(df3, ignore_index = True)\n",
    "merge=merge.append(df4, ignore_index = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_excel(\"cleaned_tweets.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
